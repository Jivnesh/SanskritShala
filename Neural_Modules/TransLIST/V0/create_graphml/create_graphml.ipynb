{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "from requests.exceptions import Timeout\n",
    "from devconvert import dev2slp, iast2slp, slp2dev, slp2iast, slp2tex, slp2wx, wx2slp, dev2wx\n",
    "from pathlib import Path\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(data_frame):\n",
    "#List indices for dataframe\n",
    "#0-'id', \n",
    "#1-'level',\n",
    "#2-'color_class',\n",
    "#3-'position',\n",
    "#4-'chunk_no',\n",
    "#5-'word',\n",
    "#6-'lemma',\n",
    "#7-'sense',\n",
    "#8-,'cng',\n",
    "#9-'pre_verb',\n",
    "#10-'morph',\n",
    "#11-'colspan',\n",
    "#12-'wordlenth',\n",
    "#13-'aux_inf,\n",
    "#14-'der_pre_verb',\n",
    "#15-'der_lemma',\n",
    "#16-'der_sense',\n",
    "#17-'der_morph',\n",
    "#18-'der_cng',\n",
    "#19-'char_pos'\n",
    "\n",
    "#    dict_ = {'source' : [], 'target' = [], 'weight' = []}\n",
    "    keys = ['source', 'target', 'key']\n",
    "    dict_ = dict.fromkeys(keys, [])\n",
    "    edges = set()\n",
    "    nodes = data_frame.values\n",
    "    for node_1 in nodes:\n",
    "        for node_2 in nodes:\n",
    "            if (not (node_1[0] == node_2[0])):#for adding edges to only those which are not conflicting\n",
    "#                if not ((node_1[19] <= node_2[19] <= (node_1[19] + node_1[12])) or (node_2[19] <= node_1[19] <= (node_2[19] + node_2[12]))) :                \n",
    "                if ((node_1[19] <= (node_1[19] + node_1[12] - 1) <= node_2[19]) or (node_2[19] <= (node_2[19] + node_2[12] - 1) <= node_1[19])):\n",
    "                    if ((not ((node_1[0], node_2[0], 1) in edges))):\n",
    "                        edges.add((node_1[0], node_2[0], 1))\n",
    "                else:\n",
    "#                    if ((not ((node_1[0], node_2[0], 2) in edges)) and ((not ((node_2[0], node_1[0], 2) in edges)))):\n",
    "                    if ((not ((node_1[0], node_2[0], 2) in edges))):\n",
    "                        edges.add((node_1[0], node_2[0], 2))\n",
    "    \n",
    "    edges_list = list(edges)\n",
    "    edges_df = pd.DataFrame(edges_list, columns = ['source', 'target', 'key'])\n",
    "    \n",
    "    g = nx.from_pandas_edgelist(edges_df, 'source', 'target', 'key', create_using = nx.DiGraph())\n",
    "    for i in sorted(g.nodes()):\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.level, index=data_frame.id).to_dict(), 'level')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.colspan, index=data_frame.id).to_dict(), 'colspan')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.aux_inf, index=data_frame.id).to_dict(), 'aux_inf')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.color_class, index=data_frame.id).to_dict(), 'color_class')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.chunk_no, index=data_frame.id).to_dict(), 'chunk_no')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.position, index=data_frame.id).to_dict(), 'position')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.length_word, index=data_frame.id).to_dict(), 'length_word')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.word, index=data_frame.id).to_dict(), 'word')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.der_pre_verb, index=data_frame.id).to_dict(), 'der_pre_verb')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.der_lemma, index=data_frame.id).to_dict(), 'der_lemma')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.der_sense, index=data_frame.id).to_dict(), 'der_sense')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.der_morph, index=data_frame.id).to_dict(), 'der_morph')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.der_cng, index=data_frame.id).to_dict(), 'der_cng')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.pre_verb, index=data_frame.id).to_dict(), 'pre_verb')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.lemma, index=data_frame.id).to_dict(), 'lemma')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.sense, index=data_frame.id).to_dict(), 'sense')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.morph, index=data_frame.id).to_dict(), 'morph')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.cng, index=data_frame.id).to_dict(), 'cng')\n",
    "        nx.set_node_attributes(g, pd.Series(data_frame.char_pos, index=data_frame.id).to_dict(), 'char_pos')\n",
    "        \n",
    "\n",
    "    return g\n",
    "\n",
    "def create_graphml(graph_, graphml_file_path):\n",
    "    nx.write_graphml_xml(graph_, graphml_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdatafromsite(inputsent, new_path, coding = 'SLP'):  # Scrapping data from site\n",
    "#    print(\"\\nInput Sentence : \" + inputsent)\n",
    "    \n",
    "    inputline = inputsent\n",
    "    inputtype = coding\n",
    "    problem = []\n",
    "    pbwords = []\n",
    "    s_type = {}\n",
    "    s_type['WX'] = 'WX'\n",
    "    s_type['SLP'] = 'SL'\n",
    "    s_type['Velthuis'] = 'VH'\n",
    "    s_type['KH'] = 'KH'\n",
    "\n",
    "    s_d = inputline\n",
    "\n",
    "    s_c = s_d.replace(\" \", \"+\")\n",
    "    # for utilising the sanskrit heritage app, the url has been specified\n",
    "\n",
    "    urlname = (\"http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph.cgi?lex=SH&st=t&us=f&cp=t&text=\" + s_c + \"&t=\" + s_type[inputtype] + \"&topic=&mode=g&corpmode=&corpdir=&sentno=\")\n",
    "\n",
    "#    urlname = (\"http://localhost/cgi-bin/SKT/sktgraph.cgi?lex=SH&st=t&us=f&cp=t&text=\" + s_c + \"&t=\" + s_type[inputtype] + \"&topic=&mode=g&corpmode=&corpdir=&sentno=\")\n",
    "\n",
    "    print(urlname)\n",
    "    try:\n",
    "        page = requests.get(urlname, timeout = 15.0)\n",
    "    except Timeout:\n",
    "        print('Request Timout')\n",
    "        return {}\n",
    "    # parsing using beautifulsoup\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    table = soup.table\n",
    "    tablebody = table.find('table', {'class': 'center'})\n",
    "    t = pd.DataFrame(columns=['id', 'level', 'color_class', 'position', 'chunk_no', 'word', 'lemma', 'sense', 'cng', 'pre_verb', 'morph', 'colspan', 'length_word', 'aux_inf', 'der_pre_verb', 'der_lemma', 'der_sense', 'der_morph', 'der_cng', 'char_pos'])\n",
    "#    t = pd.DataFrame(columns=['id', 'level', 'color_class', 'position', 'chunk_no', 'word', 'lemma', 'sense', 'cng', 'pre_verb', 'morph', 'colspan', 'length_word', 'aux_inf'])\n",
    "\n",
    "    i = 0\n",
    "    id_ = 0\n",
    "    if not (tablebody):  #### wronginputs\n",
    "        print('no table body of given inputline')\n",
    "        return {}\n",
    "    \n",
    "    cng_dict = {}\n",
    "    \n",
    "    with open(new_path, 'r') as f:\n",
    "        for line in f:\n",
    "            split_line = re.split(r'\\t|\\n', line)\n",
    "            (key, val) = (split_line[0], split_line[1])\n",
    "            cng_dict[key] = val\n",
    "    \n",
    "    # for valid entries corresponding to Wordsinsentence\n",
    "    for child in tablebody.children:\n",
    "        if (child.name == 'tr'):\n",
    "            if i < 1:\n",
    "                linechar = []\n",
    "                c = 0\n",
    "                for char in child.children:\n",
    "                    linechar.append(char.string)\n",
    "                    c += 1\n",
    "                i += 1\n",
    "                line_header = \"\".join(linechar)\n",
    "                linechunks = line_header.split(\"\\xa0\")\n",
    "                continue\n",
    "            position_ = 0\n",
    "            j = 0\n",
    "            for wordtable in child.children:\n",
    "                c = 0\n",
    "                pos_in_chunk = 0\n",
    "                for ch in linechar[0:position_]:\n",
    "                    if (re.match('\\xa0', ch) or (re.match('_',ch))):  # or (re.match('_',ch))\n",
    "                        c += 1\n",
    "                        pos_in_chunk = 0\n",
    "                    else:\n",
    "                        pos_in_chunk += 1\n",
    "                    # if the contents exist in wordtable\n",
    "                    # following assignings are carried out.\n",
    "                if (wordtable.contents):\n",
    "                    color_ = wordtable.table.get('class')[0]\n",
    "                    colspan_ = wordtable.get('colspan')\n",
    "                    word_ = wordtable.table.tr.td.string\n",
    "                    onclickdatas_ = wordtable.table.tr.td.get('onclick')\n",
    "                    show_box_data = str(re.search(r'showBox\\(\\'(.*?)\\'', onclickdatas_).group(1))\n",
    "                    for onclickdata_ in show_box_data.split(\"<br>\"):  # required splits carried out at positions stated\n",
    "                        filter_data_ = str(re.sub(r'</?a.*?>|</?i>| ✘', \"\", onclickdata_))\n",
    "                        morphslist_ = re.findall(r'{\\s?(.*?)\\s?}', filter_data_)  # .split(' | ')\n",
    "                        lsearch = re.search(r'\\[(.*)\\]\\{|\\}\\[(.*)\\]', filter_data_)\n",
    "                        msearch = re.search(r'\\{\\s?(.*)\\s?\\}\\[|\\]\\{\\s?(.*)\\s?\\}', filter_data_)\n",
    "                        mdata = \"\"\n",
    "                        ldata = \"\"\n",
    "                        if (not (msearch == None)):\n",
    "                            mdata = str(msearch.group(1)) if (not (msearch.group(1) == None)) else str(msearch.group(2))\n",
    "                        if (not (lsearch == None)):\n",
    "                            ldata = str(lsearch.group(1)) if (not (lsearch.group(1) == None)) else str(lsearch.group(2))\n",
    "                        der_lemma_string = re.search(r'\\[(.*)\\]\\{|\\}\\[(.*)\\]', ldata)\n",
    "                        der_morph_string = re.search(r'{\\s?(.*?)\\s?}', ldata)\n",
    "                        lemmas_ = str(re.sub(r'\\[(.*)\\]|{\\s?(.*?)\\s?}|\\s', \"\", ldata))\n",
    "                            \n",
    "                        if der_lemma_string == None:\n",
    "                            auxi_ = \"\"\n",
    "                            der_pre_verb = \"\"\n",
    "                            der_lemma = \"\"\n",
    "                            der_sense = \"0\"\n",
    "                            der_morph = \"\"\n",
    "                            der_cng = 1 # Not set - according to DCS's cng mapping\n",
    "                        else:\n",
    "                            der_lemma_string_value = der_lemma_string.group(1) if (not (der_lemma_string.group(1) == None)) else der_lemma_string.group(2)\n",
    "                            der_lemma_lists_ = der_lemma_string_value.split(\"-\")\n",
    "                            if (len(der_lemma_lists_) > 1):\n",
    "                                der_pre_verb = \",\".join(der_lemma_lists_[0:(len(der_lemma_lists_) - 1)])\n",
    "                                der_lemma_list = \"\".join(der_lemma_lists_[-1:]).split(\"_\")\n",
    "                            else:\n",
    "                                der_pre_verb = \"\"\n",
    "                                der_lemma_list = \"\".join(der_lemma_lists_[0]).split(\"_\")\n",
    "                            if (len(der_lemma_list) > 1):\n",
    "                                der_lemma = \"\".join(der_lemma_list[0])\n",
    "                                der_sense = \"\".join(der_lemma_list[1:(len(der_lemma_list))])\n",
    "                            else:\n",
    "                                der_lemma = \"\".join(der_lemma_list[0])\n",
    "                                der_sense = \"1\"\n",
    "                            if der_morph_string == None:\n",
    "                                der_morph = \"\"\n",
    "                            else:\n",
    "                                der_morph = str(der_morph_string.group(1))\n",
    "                                \n",
    "                            if der_morph in cng_dict.keys():\n",
    "                                der_cng = cng_dict[der_morph]\n",
    "                                \n",
    "                            auxi_ = \"\"\n",
    "                                \n",
    "                        lemmalists_ = lemmas_.split(\"-\")\n",
    "\n",
    "                        if (len(lemmalists_) > 1):\n",
    "                            preverb_ = \",\".join(lemmalists_[0:(len(lemmalists_) - 1)])\n",
    "                            lemmalist_ = \"\".join(lemmalists_[-1:]).split(\"_\")\n",
    "                        else:\n",
    "                            preverb_ = \"\"\n",
    "                            lemmalist_ = \"\".join(lemmalists_[0]).split(\"_\")\n",
    "                        if (len(lemmalist_) > 1):\n",
    "                            auxi_ = auxi_ + \" sence of lemma = \" + \"\".join(lemmalist_[1:(len(lemmalist_))])\n",
    "                            lemma_ = \"\".join(lemmalist_[0])\n",
    "                            sense_ = \"\".join(lemmalist_[1:(len(lemmalist_))])\n",
    "                        else:\n",
    "                            lemma_ = \"\".join(lemmalist_[0])\n",
    "                            sense_ = \"1\"\n",
    "                        # Temporarily assigning sense as 1 for those which do not have any sense attached explicitly. For those which have, their corresponding sense value is used\n",
    "\n",
    "                        morphs_ = ldata\n",
    "                        for morph_units in list(morphslist_):\n",
    "                            for morph_ in morph_units.split(\" | \"):\n",
    "                                if morph_ == der_morph:\n",
    "                                    continue\n",
    "                                cng_ = 0\n",
    "                                if morph_ in cng_dict.keys():\n",
    "                                    cng_ = cng_dict[morph_]\n",
    "                                \n",
    "                                t.loc[id_] = [id_, i, str(color_), pos_in_chunk, c + 1, str(word_), str(lemma_), sense_, int(cng_), str(preverb_), str(morph_), int(colspan_), int(colspan_), str(auxi_), str(der_pre_verb), str(der_lemma), der_sense, str(der_morph), der_cng, position_]\n",
    "\n",
    "                                if (re.match(r'grey_back', color_)):\n",
    "                                    if not (word_ == 'pop'):\n",
    "                                        problem.append(id_)  # filling entries to problem list\n",
    "                                    else:\n",
    "                                        id_ = id_ - 1\n",
    "                                id_ += 1\n",
    "                                \n",
    "                    position_ += int(colspan_)\n",
    "                else:\n",
    "                    position_ += 1\n",
    "            i = i + 1\n",
    "            dict_ = {'t':t,'line_header':line_header}\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphml(slp_sent, cng_list, graphml_file_name):\n",
    "    new_path = os.path.join(sys.path[0], cng_list)\n",
    "    dict_ = {}\n",
    "#    try:\n",
    "    dict_ = getdatafromsite(slp_sent, new_path)\n",
    "#    except Exception:\n",
    "#        print(\"Exception in scrapping. Possible Wrong input -> \" + slp_sent)\n",
    "#        return\n",
    "    if (dict_ == {}):\n",
    "        print(\"Empty dict from Heritage. Possible Wrong input or Timeout-> \" + slp_sent)\n",
    "        return\n",
    "    graph_ = create_graph(dict_['t'])\n",
    "    \n",
    "#    write_graphml_path = os.path.join(graphml_folder, (str(sent_id) + \".graphml\"))\n",
    "    \n",
    "    create_graphml(graph_, graphml_file_name)\n",
    "    \n",
    "def check_availability(file_name):\n",
    "    try:\n",
    "        if (Path(file_name).stat().st_size > 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def open_file(file_name):\n",
    "    if (not check_availability(file_name)):\n",
    "        return []\n",
    "    graph_input = open(file_name, mode='rb')\n",
    "    graph = nx.read_graphml(graph_input)\n",
    "    nodes = list(graph.nodes(data = True))\n",
    "    return nodes\n",
    "\n",
    "def check_graphml(graphml_file):\n",
    "# To access the graph details\n",
    "    graph_abs_file_path = os.path.join(os.getcwd(), graphml_file)\n",
    "    nodes_ = open_file(graph_abs_file_path)\n",
    "#    nodes_ = sorted(list(graph_.nodes(data = True)), key = lambda x : x[0])\n",
    "    print(len(nodes_))\n",
    "    for item in nodes_:\n",
    "        print(item)\n",
    "        first = item[1]\n",
    "        word = first['word']\n",
    "        lemma = first['lemma']\n",
    "        pre_verb = first['pre_verb'] if 'pre_verb' in first.keys() else \"\"\n",
    "        morph = first['morph']\n",
    "        sense = first['sense']\n",
    "        cng = first['cng']\n",
    "        position = first['position']\n",
    "        chunk_no = first['chunk_no']\n",
    "        length_word = first['length_word']\n",
    "        color_class = first['color_class']\n",
    "        pre_verb = first['der_pre_verb'] if 'der_pre_verb' in first.keys() else \"\"\n",
    "        pre_verb = first['der_lemma'] if 'der_lemma' in first.keys() else \"\"\n",
    "        pre_verb = first['der_sense'] if 'der_sense' in first.keys() else \"\"\n",
    "        pre_verb = first['der_morph'] if 'der_morph' in first.keys() else \"\"\n",
    "        pre_verb = first['der_cng'] if 'der_cng' in first.keys() else \"\"\n",
    "        char_pos = first['char_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph.cgi?lex=SH&st=t&us=f&cp=t&text=etac+cAnyac+ca+kOravya+prasaNgi+kawukodayam&t=SL&topic=&mode=g&corpmode=&corpdir=&sentno=\n",
      "30\n",
      "('9', {'level': 1, 'colspan': 3, 'aux_inf': ' sence of lemma = 2', 'color_class': 'cyan_back', 'chunk_no': 6, 'position': 8, 'length_word': 3, 'word': 'yam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'ya', 'sense': '2', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 40})\n",
      "('1', {'level': 1, 'colspan': 2, 'color_class': 'mauve_back', 'chunk_no': 2, 'position': 0, 'length_word': 2, 'word': 'ca', 'der_sense': '0', 'der_cng': 1, 'lemma': 'ca', 'sense': '1', 'morph': 'ind.', 'cng': 2, 'char_pos': 5})\n",
      "('27', {'level': 6, 'colspan': 3, 'color_class': 'yellow_back', 'chunk_no': 6, 'position': 5, 'length_word': 3, 'word': 'uda', 'der_sense': '0', 'der_cng': 1, 'lemma': 'uda', 'sense': '1', 'morph': 'iic.', 'cng': 3, 'char_pos': 37})\n",
      "('12', {'level': 2, 'colspan': 5, 'color_class': 'light_blue_back', 'chunk_no': 2, 'position': 1, 'length_word': 5, 'word': 'anyat', 'der_sense': '0', 'der_cng': 1, 'lemma': 'anya', 'sense': '1', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 6})\n",
      "('16', {'level': 2, 'colspan': 5, 'color_class': 'lawngreen_back', 'chunk_no': 4, 'position': 2, 'length_word': 5, 'word': 'ravya', 'der_lemma': 'ru', 'der_sense': '1', 'der_morph': 'pfp. [1]', 'der_cng': '-210', 'lemma': 'ravya', 'sense': '1', 'morph': 'n. sg. voc.', 'cng': 51, 'char_pos': 17})\n",
      "('0', {'level': 1, 'colspan': 4, 'color_class': 'mauve_back', 'chunk_no': 1, 'position': 0, 'length_word': 4, 'word': 'etat', 'der_sense': '0', 'der_cng': 1, 'lemma': 'etad', 'sense': '1', 'morph': 'ind.', 'cng': 2, 'char_pos': 0})\n",
      "('19', {'level': 2, 'colspan': 6, 'color_class': 'deep_sky_back', 'chunk_no': 6, 'position': 0, 'length_word': 6, 'word': 'kaṭukā', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kaṭuka', 'sense': '1', 'morph': 'f. sg. nom.', 'cng': 30, 'char_pos': 32})\n",
      "('15', {'level': 2, 'colspan': 2, 'color_class': 'light_blue_back', 'chunk_no': 4, 'position': 0, 'length_word': 2, 'word': 'kau', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kim', 'sense': '1', 'morph': 'm. du. nom.', 'cng': 34, 'char_pos': 15})\n",
      "('26', {'level': 5, 'colspan': 6, 'color_class': 'cyan_back', 'chunk_no': 6, 'position': 5, 'length_word': 6, 'word': 'udayam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'udaya', 'sense': '1', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 37})\n",
      "('3', {'level': 1, 'colspan': 7, 'color_class': 'lawngreen_back', 'chunk_no': 4, 'position': 0, 'length_word': 7, 'word': 'kauravya', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kauravya', 'sense': '1', 'morph': 'm. sg. voc.', 'cng': 49, 'char_pos': 15})\n",
      "('4', {'level': 1, 'colspan': 7, 'color_class': 'lawngreen_back', 'chunk_no': 4, 'position': 0, 'length_word': 7, 'word': 'kauravya', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kauravya', 'sense': '1', 'morph': 'n. sg. voc.', 'cng': 51, 'char_pos': 15})\n",
      "('14', {'level': 2, 'colspan': 2, 'color_class': 'light_blue_back', 'chunk_no': 4, 'position': 0, 'length_word': 2, 'word': 'kau', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kim', 'sense': '1', 'morph': 'm. du. acc.', 'cng': 74, 'char_pos': 15})\n",
      "('25', {'level': 5, 'colspan': 6, 'color_class': 'cyan_back', 'chunk_no': 6, 'position': 5, 'length_word': 6, 'word': 'udayam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'udaya', 'sense': '1', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 37})\n",
      "('17', {'level': 2, 'colspan': 5, 'color_class': 'lawngreen_back', 'chunk_no': 4, 'position': 2, 'length_word': 5, 'word': 'ravya', 'der_lemma': 'ru', 'der_sense': '1', 'der_morph': 'pfp. [1]', 'der_cng': '-210', 'lemma': 'ravya', 'sense': '1', 'morph': 'm. sg. voc.', 'cng': 49, 'char_pos': 17})\n",
      "('10', {'level': 2, 'colspan': 4, 'color_class': 'light_blue_back', 'chunk_no': 1, 'position': 0, 'length_word': 4, 'word': 'etat', 'der_sense': '0', 'der_cng': 1, 'lemma': 'etad', 'sense': '1', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 0})\n",
      "('24', {'level': 4, 'colspan': 6, 'color_class': 'deep_sky_back', 'chunk_no': 6, 'position': 5, 'length_word': 6, 'word': 'udayam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'udaya', 'sense': '1', 'morph': 'm. sg. acc.', 'cng': 69, 'char_pos': 37})\n",
      "('22', {'level': 3, 'colspan': 4, 'color_class': 'deep_sky_back', 'chunk_no': 6, 'position': 0, 'length_word': 4, 'word': 'kaṭu', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kaṭu', 'sense': '1', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 32})\n",
      "('13', {'level': 2, 'colspan': 5, 'color_class': 'light_blue_back', 'chunk_no': 2, 'position': 1, 'length_word': 5, 'word': 'anyat', 'der_sense': '0', 'der_cng': 1, 'lemma': 'anya', 'sense': '1', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 6})\n",
      "('6', {'level': 1, 'colspan': 8, 'color_class': 'deep_sky_back', 'chunk_no': 5, 'position': 0, 'length_word': 8, 'word': 'prasaṅgi', 'der_sense': '0', 'der_cng': 1, 'lemma': 'prasaṅgin', 'sense': '1', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 23})\n",
      "('28', {'level': 6, 'colspan': 3, 'color_class': 'yellow_back', 'chunk_no': 6, 'position': 5, 'length_word': 3, 'word': 'uda', 'der_sense': '0', 'der_cng': 1, 'lemma': 'udan', 'sense': '1', 'morph': 'iic.', 'cng': 3, 'char_pos': 37})\n",
      "('23', {'level': 3, 'colspan': 2, 'color_class': 'light_blue_back', 'chunk_no': 6, 'position': 4, 'length_word': 2, 'word': 'kā', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kim', 'sense': '1', 'morph': 'f. sg. nom.', 'cng': 30, 'char_pos': 36})\n",
      "('8', {'level': 1, 'colspan': 3, 'aux_inf': ' sence of lemma = 2', 'color_class': 'cyan_back', 'chunk_no': 6, 'position': 8, 'length_word': 3, 'word': 'yam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'ya', 'sense': '2', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 40})\n",
      "('11', {'level': 2, 'colspan': 4, 'color_class': 'light_blue_back', 'chunk_no': 1, 'position': 0, 'length_word': 4, 'word': 'etat', 'der_sense': '0', 'der_cng': 1, 'lemma': 'etad', 'sense': '1', 'morph': 'n. sg. nom.', 'cng': 31, 'char_pos': 0})\n",
      "('20', {'level': 2, 'colspan': 3, 'color_class': 'light_blue_back', 'chunk_no': 6, 'position': 8, 'length_word': 3, 'word': 'yam', 'der_sense': '0', 'der_cng': 1, 'lemma': 'yad', 'sense': '1', 'morph': 'm. sg. acc.', 'cng': 69, 'char_pos': 40})\n",
      "('7', {'level': 1, 'colspan': 6, 'color_class': 'yellow_back', 'chunk_no': 6, 'position': 0, 'length_word': 6, 'word': 'kaṭuka', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kaṭuka', 'sense': '1', 'morph': 'iic.', 'cng': 3, 'char_pos': 32})\n",
      "('18', {'level': 2, 'colspan': 8, 'color_class': 'lawngreen_back', 'chunk_no': 5, 'position': 0, 'length_word': 8, 'word': 'prasaṅgi', 'der_sense': '0', 'der_cng': 1, 'lemma': 'prasaṅgin', 'sense': '1', 'morph': 'n. sg. voc.', 'cng': 51, 'char_pos': 23})\n",
      "('21', {'level': 3, 'colspan': 4, 'color_class': 'deep_sky_back', 'chunk_no': 6, 'position': 0, 'length_word': 4, 'word': 'kaṭu', 'der_sense': '0', 'der_cng': 1, 'lemma': 'kaṭu', 'sense': '1', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 32})\n",
      "('2', {'level': 1, 'colspan': 2, 'color_class': 'mauve_back', 'chunk_no': 3, 'position': 0, 'length_word': 2, 'word': 'ca', 'der_sense': '0', 'der_cng': 1, 'lemma': 'ca', 'sense': '1', 'morph': 'ind.', 'cng': 2, 'char_pos': 12})\n",
      "('29', {'level': 7, 'colspan': 3, 'color_class': 'carmin_back', 'chunk_no': 6, 'position': 5, 'length_word': 3, 'word': 'ūda', 'der_sense': '0', 'der_cng': 1, 'lemma': 'vad', 'sense': '1', 'morph': 'pft. ac. pl. 2', 'cng': -158, 'char_pos': 37})\n",
      "('5', {'level': 1, 'colspan': 8, 'color_class': 'deep_sky_back', 'chunk_no': 5, 'position': 0, 'length_word': 8, 'word': 'prasaṅgi', 'der_sense': '0', 'der_cng': 1, 'lemma': 'prasaṅgin', 'sense': '1', 'morph': 'n. sg. acc.', 'cng': 71, 'char_pos': 23})\n"
     ]
    }
   ],
   "source": [
    "sentence = \"etac cAnyac ca kOravya prasaNgi kawukodayam\"#\"rAjakfzRA janezwA ca kapikacCuphalopamA\"\n",
    "############0123456789012345678901234567890123456789012\n",
    "############0         1         2         3         4\n",
    "graphml_file_name = \"output.graphml\"\n",
    "cng_list = \"cng_list_final\"\n",
    "slp_sent = iast2slp.convert(sentence)\n",
    "get_graphml(slp_sent, cng_list, graphml_file_name)\n",
    "check_graphml(graphml_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8344\n"
     ]
    }
   ],
   "source": [
    "## Make sure dcs10k_graphml has all garphmls for each dcs-id\n",
    "\n",
    "import os\n",
    "\n",
    "dcs10k_ids = []\n",
    "\n",
    "with open('../dcs10k_inp_gold.csv','r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    did = line.split(',')[0]\n",
    "    dcs10k_ids.append(did)\n",
    "    \n",
    "# dcs10k_ids\n",
    "    \n",
    "file_names = os.listdir('../DCS10k_graphml')\n",
    "# file_names\n",
    "dcs_files = [fn.split('.')[0] for fn in file_names]\n",
    "\n",
    "for did in dcs10k_ids:\n",
    "    if did not in dcs_files:\n",
    "        print(did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8344,sA SrIvAwyamlAdivAwAdinAnAgrAmastomasTAnaBedAd viBinnA,sA SrIvAwI amla Adi Adi nAnA grAma stoma sTAna BedAt viBid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    if line.split(',')[0] == '8344':\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://sanskrit.inria.fr/cgi-bin/SKT/sktgraph.cgi?lex=SH&st=t&us=f&cp=t&text=sA+SrIvAwyamlAdivAwAdinAnAgrAmastomasTAnaBedAd+viBinnA&t=SL&topic=&mode=g&corpmode=&corpdir=&sentno=\n",
      "Request Timout\n",
      "Empty dict from Heritage. Possible Wrong input or Timeout-> sA SrIvAwyamlAdivAwAdinAnAgrAmastomasTAnaBedAd viBinnA\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sentence = \"sA SrIvAwyamlAdivAwAdinAnAgrAmastomasTAnaBedAd viBinnA\"\n",
    "graphml_file_name = \"8344.graphml\"\n",
    "cng_list = \"cng_list_final\"\n",
    "slp_sent = iast2slp.convert(sentence)\n",
    "get_graphml(slp_sent, cng_list, graphml_file_name)\n",
    "check_graphml(graphml_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcs10k_ids = []\n",
    "\n",
    "with open('../dcs10k_inp_gold.csv','r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    did = line.split(',')[0]\n",
    "    dcs10k_ids.append(did)\n",
    "    \n",
    "dcs10k_ids_new = []\n",
    "\n",
    "with open('../dcs10k_inp_gold_new.csv','r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    did = line.split(',')[0]\n",
    "    dcs10k_ids_new.append(did)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for did in dcs10k_ids_new:\n",
    "    if did not in dcs10k_ids:\n",
    "        print(did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
